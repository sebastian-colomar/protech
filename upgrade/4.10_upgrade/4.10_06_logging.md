# DISCLAIMER
The following material is reproduced from the referenced guides and is provided exclusively for educational and training purposes.
It is provided on an "as-is" basis, without any express or implied warranties, and no responsibility is assumed for its accuracy, completeness, or applicability to any particular use.

---

# 1. Upgrade Elastic Search and Cluster Logging

## REFERENCES:
- https://docs.redhat.com/en/documentation/openshift_container_platform/4.10/html/logging/cluster-logging-upgrading

## WARNING:
> Important: You must update the OpenShift Elasticsearch Operator BEFORE you update the Red Hat OpenShift Logging Operator. You must also update both Operators to the same version.

## Procedure

1.1. Ensure that all Elastic Search and OpenShift Cluster Logging Pods, including the operator pods, are in Ready state in the `openshift-logging` namespace:
- https://console-openshift-console.apps.hub.sebastian-colomar.com/k8s/ns/openshift-operators-redhat/pods
- https://console-openshift-console.apps.hub.sebastian-colomar.com/k8s/ns/openshift-logging/pods

    ```
    oc -n openshift-operators-redhat get po

    oc -n openshift-logging get po

    ```

1.2. Ensure that the Elasticsearch cluster is healthy:

    oc exec -n openshift-logging -c elasticsearch svc/elasticsearch -- health


1.3. Ensure that the Elasticsearch cron jobs are created:

    oc -n openshift-logging get cj
    

1.4. Verify that the log store is updated and the indices are green. Verify that the output includes the `app-00000x, infra-00000x, audit-00000x, .security` indices:

    oc exec -n openshift-logging -c elasticsearch svc/elasticsearch-cluster -- indices | grep -E "health|app-|audit-|infra-|.security"
    

1.5. Verify that the log collector is healthy:

    oc -n openshift-logging get ds collector
    

1.6. Verify that the pod contains a collector container:

    oc -n openshift-logging get ds collector -o jsonpath='{range .spec.template.spec.containers[*]}{.name}{"\n"}{end}' | grep collector
    

1.7. Verify that the Kibana pod is in Ready status:

    oc -n openshift-logging get pods -l component=kibana -o jsonpath='{range .items[*]}{.metadata.name}{" -> "}{.status.conditions[?(@.type=="Ready")].status}{"\n"}{end}'
    

1.8. UPDATE the current custom catalog source of the `elasticsearch-operator` operator to use the custom mirror catalog as shown:

    alias oc=oc-4.10.64

    export CATALOG_SOURCE=mirror-redhat-operator-index-v4-10
       
    oc patch subscription elasticsearch-operator -n openshift-operators-redhat --type json --patch '[{"op": "replace", "path": "/spec/source", "value": "'${CATALOG_SOURCE}'" }]'
    
 
1.9. Ensure that all Elastic Search and OpenShift Cluster Logging Pods, including the operator pods, are in Ready state in the `openshift-logging` namespace:
- https://console-openshift-console.apps.hub.sebastian-colomar.com/k8s/ns/openshift-operators-redhat/pods
- https://console-openshift-console.apps.hub.sebastian-colomar.com/k8s/ns/openshift-logging/pods

    ```
    oc -n openshift-operators-redhat get po

    oc -n openshift-logging get po

    ```

1.10. Ensure that the Elasticsearch cluster is healthy:

    oc exec -n openshift-logging -c elasticsearch svc/elasticsearch -- health
    

1.11. Ensure that the Elasticsearch cron jobs are created:

    oc -n openshift-logging get cj
    

1.12. Verify that the log store is updated and the indices are green. Verify that the output includes the `app-00000x, infra-00000x, audit-00000x, .security` indices:

    oc exec -n openshift-logging -c elasticsearch svc/elasticsearch-cluster -- indices | grep -E "health|app-|audit-|infra-|.security"
    

1.13. Verify that the log collector is healthy:

    oc -n openshift-logging get ds collector
    

1.14. Verify that the pod contains a collector container:

    oc -n openshift-logging get ds collector -o jsonpath='{range .spec.template.spec.containers[*]}{.name}{"\n"}{end}' | grep collector
    

1.15. Verify that the Kibana pod is in Ready status:

    oc -n openshift-logging get pods -l component=kibana -o jsonpath='{range .items[*]}{.metadata.name}{" -> "}{.status.conditions[?(@.type=="Ready")].status}{"\n"}{end}'
    

1.16. UPDATE the current custom catalog source of the `cluster-logging` operator to use the custom mirror catalog as shown:

    alias oc=oc-4.10.64

    export CATALOG_SOURCE=mirror-redhat-operator-index-v4-10
     
    oc patch subscription cluster-logging -n openshift-logging --type json --patch '[{"op": "replace", "path": "/spec/source", "value": "'${CATALOG_SOURCE}'" }]'
    
 
1.17. Ensure that all Elastic Search and OpenShift Cluster Logging Pods, including the operator pods, are in Ready state in the `openshift-logging` namespace:
- https://console-openshift-console.apps.hub.sebastian-colomar.com/k8s/ns/openshift-operators-redhat/pods
- https://console-openshift-console.apps.hub.sebastian-colomar.com/k8s/ns/openshift-logging/pods

    ```
    oc -n openshift-operators-redhat get po

    oc -n openshift-logging get po

    ```

1.18. Ensure that the Elasticsearch cluster is healthy:

    oc exec -n openshift-logging -c elasticsearch svc/elasticsearch -- health
    

1.19. Ensure that the Elasticsearch cron jobs are created:

    oc -n openshift-logging get cj
    

1.20. Verify that the log store is updated and the indices are green. Verify that the output includes the `app-00000x, infra-00000x, audit-00000x, .security` indices:

    oc exec -n openshift-logging -c elasticsearch svc/elasticsearch-cluster -- indices | grep -E "health|app-|audit-|infra-|.security"
    

1.21. Verify that the log collector is healthy:

    oc -n openshift-logging get ds collector
    

1.22. Verify that the pod contains a collector container:

    oc -n openshift-logging get ds collector -o jsonpath='{range .spec.template.spec.containers[*]}{.name}{"\n"}{end}' | grep collector
    

1.23. Verify that the Kibana pod is in Ready status:

    oc -n openshift-logging get pods -l component=kibana -o jsonpath='{range .items[*]}{.metadata.name}{" -> "}{.status.conditions[?(@.type=="Ready")].status}{"\n"}{end}'
    

1.24. UPDATE the OpenShift Elasticsearch Operator:

    oc -n openshift-operators-redhat patch subscription elasticsearch-operator --type=merge -p '{"spec":{"channel":"stable-5.6","source":"mirror-redhat-operator-index-v4-10","sourceNamespace":"openshift-marketplace"}}'
    

1.25. Ensure that all Elastic Search and OpenShift Cluster Logging Pods, including the operator pods, are in Ready state in the `openshift-logging` namespace:
- https://console-openshift-console.apps.hub.sebastian-colomar.com/k8s/ns/openshift-operators-redhat/pods
- https://console-openshift-console.apps.hub.sebastian-colomar.com/k8s/ns/openshift-logging/pods

    ```
    oc -n openshift-operators-redhat get po

    oc -n openshift-logging get po

    ```

1.26. Ensure that the Elasticsearch cluster is healthy:

    oc exec -n openshift-logging -c elasticsearch svc/elasticsearch -- health
    

1.27. Ensure that the Elasticsearch cron jobs are created:

    oc -n openshift-logging get cj


1.28. Verify that the log store is updated and the indices are green. Verify that the output includes the `app-00000x, infra-00000x, audit-00000x, .security` indices:

    oc exec -n openshift-logging -c elasticsearch svc/elasticsearch-cluster -- indices | grep -E "health|app-|audit-|infra-|.security"
    

1.29. Verify that the log collector is healthy:

    oc -n openshift-logging get ds collector
    

1.30. Verify that the pod contains a collector container:

    oc -n openshift-logging get ds collector -o jsonpath='{range .spec.template.spec.containers[*]}{.name}{"\n"}{end}' | grep collector
    

1.31. Verify that the Kibana pod is in Ready status:

    oc -n openshift-logging get pods -l component=kibana -o jsonpath='{range .items[*]}{.metadata.name}{" -> "}{.status.conditions[?(@.type=="Ready")].status}{"\n"}{end}'
    

1.32. UPDATE the OpenShift Cluster Logging Operator:

    oc -n openshift-logging patch subscription cluster-logging --type=merge -p '{"spec":{"channel":"stable-5.5","source":"mirror-redhat-operator-index-v4-9","sourceNamespace":"openshift-marketplace"}}'
    

1.33. Ensure that all Elastic Search and OpenShift Cluster Logging Pods, including the operator pods, are in Ready state in the `openshift-logging` namespace:
- https://console-openshift-console.apps.hub.sebastian-colomar.com/k8s/ns/openshift-operators-redhat/pods
- https://console-openshift-console.apps.hub.sebastian-colomar.com/k8s/ns/openshift-logging/pods

    ```
    oc -n openshift-operators-redhat get po

    oc -n openshift-logging get po

    ```

1.34. Ensure that the Elasticsearch cluster is healthy:

    oc exec -n openshift-logging -c elasticsearch svc/elasticsearch -- health
    

1.35. Ensure that the Elasticsearch cron jobs are created:

    oc -n openshift-logging get cj
    

1.36. Verify that the log store is updated and the indices are green. Verify that the output includes the `app-00000x, infra-00000x, audit-00000x, .security` indices:

    oc exec -n openshift-logging -c elasticsearch svc/elasticsearch-cluster -- indices | grep -E "health|app-|audit-|infra-|.security"
    

1.37. Verify that the log collector is healthy:

    oc -n openshift-logging get ds collector
    

1.38. Verify that the pod contains a collector container:

    oc -n openshift-logging get ds collector -o jsonpath='{range .spec.template.spec.containers[*]}{.name}{"\n"}{end}' | grep collector
    

1.39. Verify that the Kibana pod is in Ready status:

    oc -n openshift-logging get pods -l component=kibana -o jsonpath='{range .items[*]}{.metadata.name}{" -> "}{.status.conditions[?(@.type=="Ready")].status}{"\n"}{end}'
    
